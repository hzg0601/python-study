{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.] nonlinear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#SVM，寻找两个足以正确分类的样本，两样本的中间平面即决策边界。\n",
    "#硬边界分类，对异常值敏感，只对线性可分有效。\n",
    "#软边际分类，允许一部分样本在边际之内，使得边际内的样本足够少，而边际宽度足够广\n",
    "#超参数C可调节边际宽度，C越大边际宽度越窄，越容易出现过拟合\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "iris=datasets.load_iris()\n",
    "X=iris['data'][:,(2,3)]\n",
    "y=(iris['target']==2).astype(np.float64)\n",
    "m=len(y)\n",
    "C=1\n",
    "svm_clf=Pipeline([('scaler',StandardScaler()),\n",
    "                 ('linear_svc',LinearSVC(C=1,loss='hinge'))])\n",
    "svm_clf.fit(X,y)\n",
    "svm_clf.predict([[5,6]])\n",
    "#SVM 直接分类，不返回概率。\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "svc_clf=Pipeline([('scaler',StandardScaler()),('SVC',SVC(kernel='linear',C=1))])\n",
    "svc_clf.fit(X,y)\n",
    "svc_clf.predict([[5,7]])\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_clf=Pipeline([('scaler',StandardScaler()),\n",
    "                  ('SGD',SGDClassifier(loss='hinge',alpha=1/(m*C)))])\n",
    "sgd_clf.fit(X,y)\n",
    "sgd_clf.predict([[5,8]])\n",
    "\n",
    "#Nonlinear SVM classification\n",
    "#如何确定是否为非线性可分与不可分？\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly_svm=Pipeline([('poly_features',PolynomialFeatures(degree=3)),\n",
    "                   ('scaler',StandardScaler()),\n",
    "                   ('svm_clf',LinearSVC(C=10,loss='hinge'))\n",
    "                  ])\n",
    "poly_svm.fit(X,y)\n",
    "print(poly_svm.predict([[5,8]]),'nonlinear')\n",
    "\n",
    "#Polynomial Kernel\n",
    "\n",
    "#增加多项式特征易于执行，适用于各种机器学习算法。但如果多项式阶数过低易造成过欠拟合，\n",
    "#过高易造成过拟合。\n",
    "#核技术可以在增加阶数的同时不增加特征数\n",
    "from sklearn.svm SVC\n",
    "poly_kernel_svm=Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('svm_clf',SVC(kernel='poly',degree=3,coef0=1,C=5))\n",
    "])\n",
    "poly_kernel_svm.fit(X,y)\n",
    "\n",
    "#增加相似性特征，即增加一个衡量所有样本与标准样本之间的相似性的函数，如Gaussian Radial Basic\n",
    "#Function 高斯径向基函数,钟型函数，0~1，1为完全相似\n",
    "#选择径向基基函数最简单的方法即在每一个样本的位置上都选一个landmark。\n",
    "#另一种方法是将m个样本n个特征的数据集变换为M个样本m个特征的数据集。\n",
    "#高斯RBF与SVM结合并不会真的增加很多特征。\n",
    "rbf_kernerl_svm=Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('svm_clf',SVC(kernerl='rbf',gamma=5,C=0.001))\n",
    "])\n",
    "#C为误差项惩罚系数，gamma为径向基函数的系数\n",
    "rbf_kernel_svm\n",
    "\n",
    "#gamma越大，钟型曲线更窄，则样本的影响范围越小，决策边界也因而更不规则。\n",
    "#因此gamma是一个正则化参数，越大越容易overfitting，越小越容易underfitting\n",
    "\n",
    "#其他核函数\n",
    "#string subsequence kernel 基于Levenshtein 距离\n",
    "#LinearSVC比SVC更快，所以首选线性核，尤其是当数据集非常大的时候。\n",
    "#当数据比较小的时候，首选Gaussian RBF。\n",
    "\n",
    "#计算复杂度\n",
    "#LinearSVC 基于liblinear library A Dual Coordinate Method for Large-scale Linear SVM\n",
    "#LinearSVC /SGDClassifier的时间复杂度O(m*n)\n",
    "#SVC基于libsvm library,时间复杂度在O(m^2*n)和O(m^3*n)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM Regression\n",
    "#SVM回归则希望支持向量见的超平面空间包含尽量多的样本，并且限制超平面间的距离在一个参数ε.\n",
    "#SVM Regression 是epsilon-敏感的\n",
    "\n",
    "#线性SVM回归\n",
    "from  sklearn.svm import LinearSVR\n",
    "svm_reg=LinearSVR(epsilon=1.5)\n",
    "svm_reg.fit(X,y)\n",
    "\n",
    "#量化行程相似度：起点-终点：里程-转弯数-速度-停车次数-无监督聚类\n",
    "#C越大，正则化程度越小\n",
    "from sklearn.svm import SVR\n",
    "svm_poly_reg=SVR(kernerl='poly',degree=2,C=100,epsilon=0.1)\n",
    "svm_poly_reg.fit(X,y)\n",
    "\n",
    "#SVM 也可用于异常检测\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RBF\n",
    "$\\phi \\gamma (\\boldsymbol{x},l)=exp(-\\gamma||\\boldsymbol{x}-l||^2)$\n",
    "其中，$l$为landmark。若landmark为0,1，则$x_2=exp(00.3\\times 1^2),x_3=exp(-0.3\\times 2^2)$\n",
    "\n",
    "#### Online SVMs\n",
    "$J(\\boldsymbol{w},b)=\\frac{1}{2}\\boldsymbol{w}^T\\cdot \\boldsymbol{w}+C\\sum_{i=1}^m{(0,1-t^{(i)}(\\boldsymbol{w}^T\\cdot \\boldsymbol{x}^{(i)}+b))}$后一项即hinge损失函数。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
